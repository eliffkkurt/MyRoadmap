{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "16. TensorFlow Tutorial 16 - Custom Training Loops.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcucDoFvJ5_G"
      },
      "source": [
        "<font color='green'> \n",
        "**Youtube - Aladdin Persson Kanalı - TensorFlow 2.0 Beginner Tutorials serisi**\n",
        "    \n",
        "TensorFlow Tutorial 16 - Custom Training Loops - Aladdin Persson anlattı.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiCsQ2FPKCBj"
      },
      "source": [
        "**Video**: [TensorFlow Tutorial 16 - Custom Training Loops](https://www.youtube.com/watch?v=_u7AVsxANes&list=PLhhyoLH6IjfxVOdVC1P1L5z5azs0XjMsb&index=16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYyUwPRhKkhW"
      },
      "source": [
        "### İçindekiler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmPWzwx3KojJ"
      },
      "source": [
        "**Loading, Preprocessing Dataset and Creating Model**\n",
        "\n",
        "**Creating Training Loop (model.fit)**\n",
        "\n",
        "**Creating Test Loop (model.evaluate)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5Jo9fSNKtUX"
      },
      "source": [
        "### <font color=\"blue\"> Giriş</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0FNmn-9KXeK"
      },
      "source": [
        "Sıfırdan nasıl training loop ve test loop yapacağımızı işleyeceğiz. Yani artık model.fit() ve model.evaluate() kullanmayacağız her şeyi kendimiz sıfırdan yazacağız. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wt1gVSzJKcvj"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSePPpYtLo-E"
      },
      "source": [
        "### 1. Loading, Preprocessing Dataset and Creating Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak6abj-FLr_j"
      },
      "source": [
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    \"mnist\",\n",
        "    split=[\"train\", \"test\"],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-JObkm5Xjv8"
      },
      "source": [
        "def normalize_img(image,label):\n",
        "  return tf.cast(image, tf.float32) / 255.0, label"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_MwZOkjXkSQ"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "ds_train = ds_train.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
        "ds_train = ds_train.cache()\n",
        "ds_train = ds_train.shuffle(ds_info.splits[\"train\"].num_examples)\n",
        "ds_train = ds_train.batch(BATCH_SIZE)\n",
        "ds_train = ds_train.prefetch(AUTOTUNE)\n",
        "\n",
        "ds_test = ds_test.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
        "ds_test = ds_test.batch(BATCH_SIZE)\n",
        "ds_test = ds_test.prefetch(AUTOTUNE)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUxJgz01McNB"
      },
      "source": [
        " model = keras.Sequential(\n",
        "     [\n",
        "      keras.Input((28,28,1)),\n",
        "      layers.Conv2D(32, 3, activation=\"relu\"),\n",
        "      layers.Flatten(),\n",
        "      layers.Dense(10, activation = \"softmax\")\n",
        "     ]\n",
        " )"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9Y107h0cvbf"
      },
      "source": [
        "### 2. Creating Training Loop (model.fit)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNjxkrDdNzRz"
      },
      "source": [
        "num_epochs = 5\n",
        "optimizer = keras.optimizers.Adam()\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "acc_metric = keras.metrics.SparseCategoricalAccuracy()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28sGkAA4Seyb"
      },
      "source": [
        "model.fit() yerine yazıyoruz bunu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOVqnXb9OSsv",
        "outputId": "aad98f53-210e-4875-b877-fc1f5e22c933"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "  print(f\"\\nStart of Training Epoch {epoch}\")\n",
        "\n",
        "  for batch_idx, (x_batch, y_batch) in enumerate (ds_train): # her epochta her batchimiz için bu işlemi yapacağız.\n",
        "    with tf.GradientTape() as tape:    # forward propagationdaki tüm operasyonları kaydetmek için\n",
        "      y_pred = model(x_batch, training=True)\n",
        "      loss = loss_fn(y_batch, y_pred) # yukarıda belirttiğimiz fonksiyon\n",
        "      \n",
        "    gradients = tape.gradient(loss, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
        "    acc_metric.update_state(y_batch, y_pred) \n",
        "\n",
        "  train_acc = acc_metric.result()\n",
        "  print(f\"Accuracy over epoch {train_acc}\")\n",
        "  acc_metric.reset_states() # bir sonraki epoch için sıfırlıyoruz accuracyi.\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Start of Training Epoch 0\n",
            "Accuracy over epoch 0.9089999794960022\n",
            "\n",
            "Start of Training Epoch 1\n",
            "Accuracy over epoch 0.913433313369751\n",
            "\n",
            "Start of Training Epoch 2\n",
            "Accuracy over epoch 0.9159166812896729\n",
            "\n",
            "Start of Training Epoch 3\n",
            "Accuracy over epoch 0.9189333319664001\n",
            "\n",
            "Start of Training Epoch 4\n",
            "Accuracy over epoch 0.9214000105857849\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3m7KyspTSmrx"
      },
      "source": [
        "### 3. Creating Test Loop (model.evaluate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgROV9HxStaD"
      },
      "source": [
        "model.evaluate() yerine bunu yazdık."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5l_cX5KMSoC7",
        "outputId": "676f2049-073e-40ac-c315-eb25830f0518"
      },
      "source": [
        "# Birden fazla epoch için çalıştırmamız gerekmiyor. Data setini bir kere çalıştırmamız yeterli.\n",
        "\n",
        "for x, y in ds_test: \n",
        "  y_pred = model(x, training=False)\n",
        "  acc_metric.update_state(y, y_pred)\n",
        "\n",
        "test_acc = acc_metric.result()\n",
        "print(f\"Accuracy over Test Set: {test_acc}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy over Test Set: 0.9085999727249146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXIQkUtbTgVL"
      },
      "source": [
        "* `for batch_idx, (x_batch, y_test) in enumerate(ds_test):` burada batch_idx kullanmamıza ve dolayısıyla enumerate kullanmamıza gerek yok ama bazen ihtiyaç olabiliyor. Ben bunun yerine `for x, y in ds_test:` yazdım.\n",
        "\n",
        "* ` with tf.GradientTape() as tape:` buna ihtiyacımız yok çünkü gradientleri toplamayacağız."
      ]
    }
  ]
}