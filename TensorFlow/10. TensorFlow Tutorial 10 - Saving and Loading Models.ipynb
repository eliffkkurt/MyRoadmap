{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10. TensorFlow Tutorial 10 - Saving and Loading Models.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeY7Jm5qYxqH"
      },
      "source": [
        "<font color='green'> \n",
        "**Youtube - Aladdin Persson Kanalı - TensorFlow 2.0 Beginner Tutorials serisi**\n",
        "    \n",
        "TensorFlow Tutorial 10 - Saving and Loading Models - Aladdin Persson anlattı.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVwGUVqkY3dm"
      },
      "source": [
        "**Video**: [TensorFlow Tutorial 10 - Saving and Loading Models](https://www.youtube.com/watch?v=idus3KO6Wic&list=PLhhyoLH6IjfxVOdVC1P1L5z5azs0XjMsb&index=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5HnoTgbY-TV"
      },
      "source": [
        "### İçindekiler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUdmQyE8ZDPG"
      },
      "source": [
        "**Loading Dataset**\n",
        "\n",
        "**Preprocessing Dataset**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glMm4ZkzZElv"
      },
      "source": [
        "### Kaynaklar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHvTV1NGYq5d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9WARhc4nN1q"
      },
      "source": [
        "### <font color=\"blue\"> Giriş</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gP8nwNzGnSJp"
      },
      "source": [
        "Bu notebookta amaç modelin weightlerini ve tüm modeli nasıl save ve load edeceğimizi öğreneceğiz."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsoApc2lkZCH"
      },
      "source": [
        "##### **1. How to save and load model weights** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3W1Jef2cMrc"
      },
      "source": [
        "##### **2. Save and load entire model (serializing model)**\n",
        "Tüm modeli kaydedip yüklerken, bir data structure olarak kaydedilecek ve bu, modelin tensorflow javascript, tensorflow lite gibi farklı tensorflow frameworklerine yüklenebileceği anlamına geliyor. Yani örneğin PC'nizde bir modeli eğitebilir ve diyelim ki onu üretime almak ve bir uygulama yapmak istiyorsunuz, daha önce eğittiğiniz modeli yükleyebilirsiniz ve herhangi bir dönüştürme yapmanıza gerek olmaz.\n",
        "\n",
        "Tüm modeli yüklediğimizde:\n",
        "* Weightler kaydedilecek. \n",
        "* Model architecture'ı (model mimarisi) kaydedilecek. Bu şekilde modelin koduna ihtiyacımız kalmayacak.\n",
        "* Training configurationı da (eğitim yapılandırmasını) da kaydedecek, böylece model.compile() dosyasına göndereceğiniz şey bu olacaktır.\n",
        "* Optimizer ve state'leri kaydedecek. For example if you're using the Adam optimizer it's gonna keep track of the exponential weighted averages and that's internal to the optimizer. \n",
        "\n",
        "Ve son olarak, optimize ediciyi ve durumları da kaydedecek. Örneğin, Adam optimize ediciyi kullanıyorsanız, üstel ağırlıklı ortalamaları takip edecektir ve bu, optimize edicinin içindedir.\n",
        "\n",
        "- And then lastly it's also going to save the optimizer and states. So for example if you're using the Adam optimizer it's gonna keep track of the exponential weighted averages and that's internal to the optimizer. Örneğin, yalnızca weightleri kaydediyorsanız, modelden weightleri her yüklediğinizde optimize edici durumlar sıfırlanacaktır.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mnl31YpKnRez"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BR1FBSn4n8Y0"
      },
      "source": [
        "### 1. Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2o3CM3KnugQ"
      },
      "source": [
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grAa8-MOoRaH",
        "outputId": "b469ed65-ff38-4520-fd29-4ef82c271702"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIMi7FBiom7y"
      },
      "source": [
        "### 2. Preprocessing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaM0QG-PolVi"
      },
      "source": [
        "x_train = x_train.reshape(-1, 28 * 28).astype(\"float32\") / 255.0\n",
        "x_test = x_test.reshape(-1, 28*28).astype(\"float32\") / 255.0"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcRXhUsRpHLq"
      },
      "source": [
        "### 3. Creating Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyF3Q5Q_bQe9"
      },
      "source": [
        "3 farklı model yazdık."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFCVeSw9tDW2"
      },
      "source": [
        "##### <font color=\"green\">İlkinde Sequential API kullandık. </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQwSWmH_pA2O"
      },
      "source": [
        "model1 = keras.Sequential(\n",
        "    [\n",
        "     layers.Dense(64, activation='relu'),\n",
        "     layers.Dense(10)\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hu64EwjXtGjX"
      },
      "source": [
        "##### <font color=\"green\">İkincisinde aynı modeli Functional API kullanarak yazdık. </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2snYw-8YrTUG"
      },
      "source": [
        "inputs = keras.Input(784)\n",
        "x = layers.Dense(64, activation='relu')(inputs)\n",
        "outputs = layers.Dense(10)(x)\n",
        "model2 = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b48XsenDbTgU"
      },
      "source": [
        "##### <font color=\"green\">Üçüncüsünde modelimizi subclassing kullanarak yazdık. </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmEtX830bSgS"
      },
      "source": [
        "class MyModel(keras.Model):\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.dense1 = layers.Dense(64, activation='relu')\n",
        "    self.dense2 = layers.Dense(10)\n",
        "\n",
        "  def call(self, input_tensor):\n",
        "    x = tf.nn.relu(self.dense1(input_tensor))\n",
        "    return self.dense2(x)\n",
        "\n",
        "model3 = MyModel()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUeNBTtKky5l"
      },
      "source": [
        "### 4. Specify Model Build From the Three API's"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzNWg4rSl4Bb"
      },
      "source": [
        "##### <font color=\"green\">İlk modeli çalıştırıyoruz.</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHyAONp7lB2n"
      },
      "source": [
        "model = model1"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOIUxcwglKx2"
      },
      "source": [
        "model.compile(\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer = keras.optimizers.Adam(),\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMgYWs6JlYmN",
        "outputId": "0298115e-31fc-47fe-c949-d619d62dd056"
      },
      "source": [
        "model.fit(x_train, y_train, batch_size=32, epochs=2, verbose=2)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1875/1875 - 6s - loss: 0.3107 - accuracy: 0.9123\n",
            "Epoch 2/2\n",
            "1875/1875 - 3s - loss: 0.1503 - accuracy: 0.9565\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0fcdb81250>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5pGqp1NlgKp",
        "outputId": "b5515b0e-a584-4dc5-8252-330bdd6d9c8c"
      },
      "source": [
        "model.evaluate(x_test, y_test, batch_size=32, verbose=2)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 1s - loss: 0.1286 - accuracy: 0.9620\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.12860487401485443, 0.9620000123977661]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLAcvD31tcqG"
      },
      "source": [
        "### 5. How to Save and Load Model Weights\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EriI3ORxthyS"
      },
      "source": [
        "model.save_weights('saved_model/') "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxsCUZIOmbI9"
      },
      "source": [
        "`model.save_weights('saved_model/')`: bir klasör adı yazıyoruz parantez içine. Notebookun bulunduğu yerde bu adda bir klasör açıyor. Scripti çalıştırdığımız yere baktığımızda saved_model adında bir klasör göreceğiz ve weightlerin kaydedildiği dosyalar bu klasörün içinde yer alıyor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXe4mGuptnSh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olf-OGYstnME"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwBg-_gVtnBL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDAZyB5DtzLE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2PdxGKRtnrX"
      },
      "source": [
        "### 5. Save and Load Entire Model (Serializing Model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5mCiJm3uWnx"
      },
      "source": [
        "- It will save the weights.\n",
        "- It will save the model arhitecture.\n",
        "- It will save the training configuration (model.compile())\n",
        "- Optimizer and states"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxvO-Br5t4za"
      },
      "source": [
        "Tüm modeli kaydetmek istediğimizde data structure olarak kaydedecek. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXX6PTRmtyai"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}